## Application of an Open Publishing Framework to an Emerging Public health Crisis

### Abstract

### Introduction

As international attention remains focused on the ongoing public health crisis, the scientific community has responded by mobilizing resources and turning much of its attention to the virus and disease.
This rapid influx of information is disseminated by traditional publishing mechanisms, preprint servers, and press releases, which provide a venue for scientists to release findings without undergoing the formal publication process.
While having information available is valuable to efforts to understand and combat COVID-19, many contributions come from researchers across a wide range of fields who have varying degrees of experience working on coronaviruses and related topics.
The volume of information available, much of which has not gone through rigorous peer review, presents a significant challenge to individual efforts to keep abreast of the state of COVID-19 research [@doi:10.1038/s42254-020-0175-7].
However, research on these topics is proceeding so rapidly that any static review is likely to quickly become dated.
Our goal as a community is to consolidate information about the virus in the context of related viruses and to synthesize rapidly emerging literature centered on the diagnosis and treatment of COVID-19.
We used an open publishing framework, Manubot [@doi:10.1371/journal.pcbi.1007128], to manage hundreds of contributions from the community to create a living, scholarly document.
We designed software to generate figures, such as Figure @fig:csse-deaths, that automatically update using external data sources.
Our primary goal is to sort and distill informative content out of the overwhelming flood of information [@doi:10.1038/s42254-020-0175-7] and help the broader scientific community become more conversant on this critical subject.
Thus, our approach has been to develop a real-time, collaborative effort that welcomes submissions from scientists worldwide into this ongoing effort.
This document represents the first snapshot, which aims to reflect the state of the field as of October, 2020.
We plan to refine and expand this document until technologies to mitigate the pandemic are widely available.

In an effort to keep pace as new information about COVID-19 and SARS-CoV-2 becomes available, this project is an open, collaborative effort that invited contributions from the scientific community broadly, similar to previous efforts to develop collaborative reviews [@doi:10.1098/rsif.2017.0387; @url:https://greenelab.github.io/deep-review].
Contributors were recruited by word of mouth and on Twitter.
Existing efforts to train early-career scientists were also integrated: Appendix A contains summaries written by the students, post-docs, and faculty of the Immunology Institute at the Mount Sinai School of Medicine [@url:https://github.com/ismms-himc/covid-19_sinai_reviews; @doi:10.1038/s41577-020-0319-0], and two of the authors were recruited through the American Physician Scientist Association's Virtual Summer Research Program [@url:https://www.physicianscientists.org/page/summer-research-pilot-program].
The project was managed through GitHub [@url:https://github.com/greenelab/covid19-review] using Manubot [@doi:10.1371/journal.pcbi.1007128] to continuously generate a version of the manuscript online [@url:https://greenelab.github.io/covid19-review].
Contributors developed text that was proposed through GitHub's pull request system and then reviewed and approved by at least one other author.
While this document reflects the current version of record, the online version will continue to be developed as information about the pandemic emerges.
Below, we will describe the processes used to synthesize the literature.

### Technical Infrastructure

#### Collaborative Writing and Manuscript Generation

Manubot [@doi:10.1371/journal.pcbi.1007128] is a collaborative framework developed to adapt open-source software development techniques and version control for manuscript writing.
Here, Manubot was used to generate a manuscript from text maintained using GitHub, a popular, online version control interface.
The GitHub implementation allowed users to contribute either using git on the command line or using the GitHub user interface, and we developed documentation for users with less experience with this platform.
Manubot also provides a functionality to create a bibliography using digital object identifiers (DOIs), website URLs, or other identifiers such as PubMed identifiers and arXiv IDs.
Due to the needs of this project, project contributors also implemented new features in Manubot and [Zotero](https://www.zotero.org/), which Manubot uses to extract metadata for some types of citations.
These features support directly citing clinical trial identifiers such as `clinicaltrials:NCT04292899` [@clinicaltrials:NCT04292899].
Finally, Manubot and GitHub Actions continuous integration allowed for scripted updates to be run each time the manuscript was generated.
These scripts were used to check that the manuscript was built correctly, run spellchecking, and cross-reference the manuscripts cited in this review, summarized in Appendix A, and discussed in the project's issues and pull requests.

#### Data Analysis and Visualization

The combination of Manubot and GitHub Actions also made it possible to dynamically update information such as statistics and visualizations in the manuscript.
Data about worldwide cases and deaths from the COVID-19 Data Repository by the Center for Systems Science and Engineering at Johns Hopkins University [@https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series] were read using a Python script to generate Figure @fig:csse-deaths.
Similarly, Figure @fig:ebm-trials and clinical trials statistics were generated based on data from the University of Oxford Evidence-Based Medicine Data Lab's COVID-19 TrialsTracker [@doi:10.5281/zenodo.3732709].
In both cases, frequency data were plotted using Matplotlib [@doi:10.1109/MCSE.2007.55] in Python.
Figure @fig:ebm-map was generated using the countries associated with the trials listed in the COVID-19 TrialsTracker, converting the country names to 3-letter ISO codes using pycountry or manual adjustment when necessary, and visualizing the geographic distribution of trial recruitment using geopandas.
<!-- Is this figure going to be included? #673 -->

GitHub Actions runs a nightly workflow to update these external data and regenerate the statistics and figures for the manuscript.
The workflow uses the GitHub API to detect and save the latest commit of the external data sources, which are both GitHub repositories.
It then downloads versioned data from that snapshot of the external repositories and runs bash and Python scripts to calculate the desired statistics and produce the summary figures.
The statistics are stored in JSON files that are accessed by Manubot to populate the values of placeholder template variables dynamically every time the manuscript is built.
For instance, the template variable {% raw %}`{{ebm_trials_results}}`{% endraw %} in the manuscript is replaced by the actual number of clinical trials with results, {{ebm_trials_results}}.
The template variables also include versioned URLs to the dynamically updated figures.
The JSON files and figures are stored in the `external-resources` branch of the manuscript's GitHub repository, which acts as versioned storage.
The GitHub Actions workflow automatically adds and commits the new JSON files and figures to the `external-resources` branch every time it runs, and Manubot uses the latest version of these resources when it builds the manuscript.

The workflow file is available from <https://github.com/greenelab/covid19-review/blob/master/.github/workflows/update-external-resources.yaml> and the scripts are available from <https://github.com/greenelab/covid19-review/tree/external-resources>.
The Python package versions are available in <https://github.com/greenelab/covid19-review/blob/external-resources/environment.yml>.
<!-- These files are archived with [Software Heritage](...). -->

### Article Selection and Evaluation

Relevant articles were identified and submitted as issues on [GitHub](https://github.com/greenelab/covid19-review) for review.
Articles were classified as _diagnostic_, _therapeutic_, or _other_, and a template was developed to guide the review of papers and preprints in each category.
Following a framework often used for assessing medical literature, the review consisted of examining methods used in each relevant article, assignment (whether the study was observational or randomized), assessment, results, interpretation, and how well the study extrapolates [@doi:10.5014/ajot.60.4.367].
For examples of each template, please see Appendices B-D.

#### Diagnostic Papers

##### Methods

Reviewers began by describing the study question(s) being investigated by the article.
They then described the study population, the sample size, the prevalence of the disease in the study population, countries / regions considered in case of human subjects, demographics of participants, the setting, and any remaining inclusion / exclusion criteria considered.
They then described the reference test or "gold standard," if one was utilized.

##### Assignment

Reviewers described how new and reference tests were assigned, including additional relevant details about the study design.
For example, reviewers were asked whether the diagnostic test resulted in rigorous assignments of case status or was biased towards sicker or healthier individuals.

##### Assessment

Reviewers described how the test was performed.
For example, for both standard and reference tests, reviewers described technical details of assays used, when measurements were taken and by whom.
Subsequently, they described how individuals were classified as positive or negative cases and whether results were precise and reproducible with repeated tests.
Reviewers described whether there were any missing data, whether some participants underwent only one test, or whether there were individuals with inconclusive results.

##### Results

Reviewers reported the estimated sensitivity, specificity, positive predictive value (PPV), and negative predicted value (NPV), as well as confidence bounds around these measures, if provided.

##### Interpretation

Reviewers reported how well the test ruled in or ruled out disease based on the population, if there were identified side effects, and patient adherence.

##### Extrapolation

Reviewers described how well this test will extrapolate outside the measured population.

#### Therapeutic Papers

##### Methods

Reviewers began by describing the study question(s) being investigated by the article.
They then described the study population, the sample size, the prevalence of the disease in the study population, countries / regions considered in case of human subjects, demographics of participants, the setting, and any remaining inclusion / exclusion criteria considered.

##### Assignment

Reviewers described how the treatment is assigned, whether it was an interventional or observational study, whether randomization took place, etc.

##### Assessment

###### Outcome Assessment

Reviewers described the outcome that was assessed and evaluated whether it was appropriate given the underlying study question.
They described whether there were any missing data such as whether there were individuals lost to follow up.
They then describe whether there were any potential sources of bias such as lack of blinding in a randomized controlled trial.

###### Statistical Methods Assessment

Reviewers described which statistical methods were used for inference and whether applied methods were appropriate for the study.
They then described whether adjustments were made for possible confounders.

##### Results

Reviewers described the estimated association between the treatment and outcome.
They described measures of confidence or statistical significance, if provided.

##### Interpretation

Reviewers described whether a causal claim could be made.
They described whether any side effects or interactions with other drugs were identified, as well as any subgroup findings.

##### Extrapolation

Reviewers describe how the study may extrapolate to a different species or population.

### Conclusions

![**Summary of the relationships among topics covered in this review.**](images/N000-overview.png){#fig:overview secno=1}

Several review articles on aspects of COVID-19 have already been published.
These have included reviews on the disease epidemiology [@doi:10.1016/j.molmed.2020.02.008], immunological response [@doi:10.1016/j.immuni.2020.05.002], diagnostics [@doi:10.1126/scitranslmed.abc1931], and pharmacological treatments [@doi:10.1016/j.immuni.2020.05.002; @doi:10.1001/jama.2020.6019].
Others [@doi:10.1038/d41591-020-00026-w; @doi:10.1001/jama.2020.12839] provide narrative reviews of progress on some important ongoing COVID-19 research questions.
With the worldwide scientific community uniting during 2020 to investigate SARS-CoV-2 and COVID-19 from a wide range of perspectives, findings from many disciplines are relevant on a rapid timescale to a broad scientific audience.
Additionally, many findings are published as preprints, which are available prior to going through the peer review process.
As a result, centralizing, summarizing, and critiquing new literature broadly relevant to COVID-19 can help to expedite the interdisciplinary scientific process that is currently happening at an advanced pace.
We are particularly interested in providing background to the development of diagnostic, prophylactic, and therapeutic approaches to COVID-19.
Two major concerns within diagnosis include the detection of current infections in individuals with and without symptoms, and the detection of past exposure without an active infection.
In the latter category, identifying whether individuals can develop or have developed sustained immunity is also a major consideration.
The development of high-throughput, affordable methods for detecting active infections and sustained immunity will be critical to understanding and controlling the disease.
The identification of interventions that can mitigate the effect of the virus on exposed and infected individuals is a significant research priority.
Some possible approaches include the identification of existing pharmaceuticals that reduce the severity of infection, either by reducing the virus' virulence (e.g., antivirals) or managing the most severe symptoms of infection.
Due to the long timeline for the development of novel pharmaceuticals, in most cases, research surrounding possible pharmaceutical interventions focuses on the identification and investigation of existing compounds whose mechanisms may be relevant to COVID-19.
Other foci of current research include the identification of antibodies produced by survivors of COVID-19 and the development of vaccines.
Understanding the mechanisms describing host-virus interactions between humans and SARS-CoV-2 is thus critical to identifying candidate therapeutics.
An overview of the topics covered is visualized in Figure @fig:overview.
Thus, in this review, we seek to consolidate information about efforts to develop strategies for diagnosis and therapeutics as new information is released by the scientific community.
We include information from both traditional peer-reviewed scientific literature and from preprints, which typically have not undergone peer review but have been critically evaluated by the scientists involved in this effort.
The goal of this manuscript is to present preliminary findings within the broader context of COVID-19 research and to identify the broad interpretations of new research, as well as limitations to interpretability.
